\begin{abstract}

Melanoma is the most dangerous and deadliest skin cancer type causing over \$8 billion in health care costs annually in the United States alone. In this work we investigate the application of state-of-the-art computer vision Transformer based architectures on the task of semantic skin lesion segmentation. We compare the Medical Transformer and TransUNet models with the widely used U-Net, a convolutional neural network (CNN) specifically developed for medical image segmentation, to study their performance on the melanoma segmentation challenge dataset published by the International Skin Imaging Collaboration (ISIC). We show that vision Transformers achieve better results than their established CNN based counterparts in some aspects as expressed by the specificity metric, perform comparably well as measured by accuracy or Dice Coefficient, but show evident weaknesses as revealed by the threshold Jaccard Index metric. It is worth noticing that the performance gains are often minimal and come with higher computational cost. Furthermore, our work shows that an appropriate image pre-processing and data augmentation play a crucial role in medical segmentation tasks as data is often scarce and shows varying quality characteristics.

% \begin{itemize}
%   \item One paragraph summary of the entire paper
%   \item include the results and the implications of those results (i.e. social, business, etc.)
% \end{itemize}

\end{abstract}
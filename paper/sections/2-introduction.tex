\section{Introduction}

Malignant melanoma is one of the most dangerous and one of the rapidly growing diseases in the world. An early detection of melanoma can be very useful in curing the disease as the treatment becomes more complex at later stages. Unfortunately, despite the amenability of melanoma to early diagnosis through simple visual inspection, many patients continue to be diagnosed with more advanced disease. Adoption of technological aids for melanoma detection has been slow due to cost. With the advent of smart phone based digital cameras, it is now feasible to use high resolution images from digital cameras for diagnosis. Automated melanoma segmentation would help immensely for early diagnosis \citep{isic-2021-about}.

\par
With the introduction of deep learning architectures, semantic image segmentation, a pixel wise categorization and semantic grouping to detect coherent parts of an image, has made significant advancements in recent years. Among different approaches, convolutional neural network (CNN) and Transformer based models are two types of architectures which have shown very encouraging results.


\subsection{Related Work}
One of the seminal works in the CNN based models is the U-Net architecture by \citep{unet-2015-ronneberger}. The architecture comprises two parts – the encoder, a contracting path, downsamples images by using max-pooling layers and extracts relevant features using 3 by 3 convolutions. This compression helps to address speed issues. The decoder, an expansive path, upsamples images by using 2 by 2 up-convolutions and enriches them with a corresponding cropped feature map from the contracting path (skip-connections) which helps the model to preserve spatial information and hence localization accuracy. The symmetry of the contracting and expanding paths gives the architecture its u-shaped appearance \citep{unet-2015-ronneberger}. U-Net has been established as the de facto standard in medical image segmentation, however there are some drawbacks to this architecture such as  the problem of vanishing gradients during training on high-resolution images as the model only captures the local attention \citep{transformers-2020-dosovitskiy}. Based on U-Net, other work has been proposed to improve the model’s performance. The authors of Double-UNet \citep{double_unet-2020-jha} use two layers of U-Net along with Atrous Spatial Pyramid pooling whereas DeepLab \citep{deeplab-2016-chen} tackles the problem of reduced feature resolution by using atrous convolution. Compared to the work based on U-Net, \citep{nabla-2019-alom} present a new segmentation model, the Nabla-N architecture, which proposes to use better feature fusion techniques in the decoding layer to achieve a better feature representation. Their experimental results show higher accuracy on segmentation tasks, reaching around 87\% testing accuracy for dermoscopic classification of skin cancer on ISIC 2018 dataset. \citep{data_purification-2019-bisla} propose a data augmentation technique to improve the performance of U-Net architecture. \citep{melonama_diagnosis-2021-codella} utilize a different approach for image segmentation, a Mask and Region based Convolutional Neural Network (M R\_CNN) for creating "Region of Interest". \citep{ensambles-2016-codella} propose a data augmentation technique to improve performance on segmentation performance. They successfully show the merits of using non-linear distortions to improve segmentation performance.

\par
CNNs have been shown to be highly effective in various computer vision problems. Convolutions bring important properties such as sparse interactions or weight sharing which form a strong and useful inductive bias (ability to generalize) for vision tasks. However, medical image analysis applications come with additional challenges like a 3D structure (MRI) or a small number of labeled images. To tackle those challenges the authors of \citep{convolution_free-2021-karimi} propose a new model based entirely on self-attention.

\par
Transformers have been widely used in NLP tasks to learn patterns from sequences, however they suffer from quadratic complexity. When applied to images, the attention mechanism of the transformers can mimic convolutions. In addition to this, transformers learn the spatial relationships between high level image features. Vision Transformers \citep{transformers-2020-dosovitskiy} is an influential paper as it classifies images completely using transformer architecture and removes the need of CNN in vision. The CNN based architecture only captures local attention while the Transformer based vision architecture captures global attention over every pixel of the image.  It opens the door for a lot of interesting research and ideas. The paper also shows that it takes less time to train the Vision Transformer model (ViT) as compared to ResNet-based architecture.

\par
TransUNet \citep{transunet-2021-chen} is inspired by ViT \citep{transformers-2020-dosovitskiy} and combines the U-Net and vision transformer based architecture by using cascading CNN’s and Transformers for downsampling. It then uses skip connections in the upsampling path, hence persevering localized as well as global information.

\par
Medical Transformer \citep{medical_transformer-2021-valanarasu} extends the work of \citep{transformers-2020-dosovitskiy} by adding the Local-Global strategy to capture the local, finer image features and to model the long-range  dependencies present in an image. They also add an additional control mechanism in the self-attention module called Gated Axial-Attention with four control gates defined as learnable parameters. Compared to \citep{transunet-2021-chen} which depends on pre-trained weights obtained by training on a large image corpus, the authors of \citep{medical_transformer-2021-valanarasu} explore the feasibility of applying transformers working on only self-attention mechanisms as an encoder. In medical applications pre-training on large-scale image datasets becomes problematic as there is often only a small amount of labeled images available as data annotation is very expensive and requires expert knowledge.

\par
Similar to \citep{medical_transformer-2021-valanarasu} the work of \citep{convolution_free-2021-karimi} focuses on neural networks for medical image segmentation but extends to the 3D space. The authors show that their proposed model can be effectively trained with only 20-200 labeled images and also propose methods that can improve the segmentation accuracy when large corpora of unlabeled training images are available. In contrast to \citep{medical_transformer-2021-valanarasu} and \citep{transformers-2020-dosovitskiy} that use some convolutional layers for feature extraction, \citep{convolution_free-2021-karimi} relinquish all convolutional layers and explore self attention-based deep neural networks only.


\subsection{Scope and Focus}

The focus of this work is to investigate the application of state-of-the-art computer vision Transformer based architectures on the task of semantic skin lesion segmentation. We conduct a set of experiments to understand and compare the performance of selected CNN based and Transformer based models on the skin lesion segmentation dataset published by the International Skin Imaging Collaboration (ISIC). We build upon the work of \citep{medical_transformer-2021-valanarasu} and \citep{transunet-2021-chen} and extend the application of Medical Transformer and TransUNet to skin lesion segmentation.  We hypothesize that Transformer based architectures will perform better than CNN based models, namely U-Net \citep{unet-2015-ronneberger}, on this specific image segmentation task. The code of our work can be viewed on GitHub\footnote{\url{https://github.com/jhabr/xcs229ii_final_project}}.

% \begin{itemize}
%   \item Describe the topic under investigation.
%   \item Summarize prior research in this area.
%   \item Identification of unresolved issues that your current paper will address.
%   \item Provides a overview of the paper and sections to follow.
% \end{itemize}


% Lit references (to be removed):
% \begin{itemize}
%   \item U-Net: \citep{unet-2015-ronneberger}
%   \item Double U-Net: \citep{double_unet-2020-jha}
%   \item medical transformer: \citep{medical_transformer-2021-valanarasu}
%   \item transformers for image recognition: \citep{transformers-2020-dosovitskiy}
%   \item convolution free: \citep{convolution_free-2021-karimi}
%   \item nabla: \citep{nabla-2019-alom}
%   \item deeplab: \citep{deeplab-2016-chen}
%   \item transU-Net: \citep{transunet-2021-chen}
%   \item drinet: \citep{drinet-2018-chen}
%   \item dataset: \citep{isic-2018-segmentation}
%   \item segmentation winners: \citep{skin_segmentation-2019-jahanifar}
%   \item challange paper: \citep{challenge-2018-codella}
%   \item data purification: \citep{data_purification-2019-bisla}
%   \item ensambles: \citep{ensambles-2016-codella}
%   \item melanoma diagnosis: \citep{melonama_diagnosis-2021-codella}
% \end{itemize}

% From project proposal:
% \begin{itemize}
%   \item \citep{wiki-2021-melanoma}
%   \item \citep{acs-2021-melanoma}
%   \item \citep{isic-2018-segmentation}
% \end{itemize}
